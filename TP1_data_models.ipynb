{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "946 ms ± 15.8 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2177.33 MiB, increment: 426.41 MiB\n",
      "171 ms ± 7.71 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2196.59 MiB, increment: 55.38 MiB\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "\n",
    "\n",
    "def loading_from_csv_DictReader(filename):\n",
    "    with open(filename, encoding=\"utf8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        data = list(reader)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def extract_top5_DictReader(data):\n",
    "    \n",
    "    for artist in data:\n",
    "        artist['popularity'] = float(artist['popularity'])\n",
    "    top5_artists = sorted(data, key=lambda x: x['popularity'], reverse=True)[:5]\n",
    "    \n",
    "    return [{'name': artist['name'], 'popularity': artist['popularity']} for artist in top5_artists]\n",
    "\n",
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n",
    "filename = '/Users/theoverdelhan/Documents/EDUCATION/FG4A DATA/Data models/artists_rev1.csv'\n",
    "\n",
    "\n",
    "time_measures={}\n",
    "memory_measures={}\n",
    "\n",
    "# Mesurer le temps et la mémoire pour charger les données\n",
    "time_measures[\"csv_dictreader_load\"] = %timeit -o -r 3 -n 10 loading_from_csv_DictReader(filename)\n",
    "memory_measures[\"csv_dictreader_load\"] = %memit -c -o -r 3 -i 0.001 loading_from_csv_DictReader(filename)\n",
    "\n",
    "\n",
    "# Charger les données pour l'extraction\n",
    "data = loading_from_csv_DictReader(filename)\n",
    "\n",
    "# Mesurer le temps et la mémoire pour l'extraction des 5 meilleurs artistes\n",
    "time_measures[\"csv_dictreader_extract\"] = %timeit -o -r 3 -n 10 extract_top5_DictReader(data)\n",
    "memory_measures[\"csv_dictreader_extract\"] = %memit -c -o -r 3 -i 0.001 extract_top5_DictReader(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of rows:  1162095\n",
      "Example of rows extracted:  [{'id': '0DheY5irMjBUeLybbCUEZ2', 'followers': '0.0', 'genres': '[\"\"]', 'name': 'Armid & Amir Zare Pashai feat. Sara Rouzbehani', 'popularity': '0'}, {'id': '0DlhY15l3wsrnlfGio2bjU', 'followers': '5.0', 'genres': '[\"\"]', 'name': 'ปูนา ภาวิณี', 'popularity': '0'}, {'id': '0DmRESX2JknGPQyO15yxg7', 'followers': '0.0', 'genres': '[\"\"]', 'name': 'Sadaa', 'popularity': '0'}]\n"
     ]
    }
   ],
   "source": [
    "data = loading_from_csv_DictReader(filename)\n",
    "print(\"Nb of rows: \",len(data))\n",
    "print(\"Example of rows extracted: \", data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Justin Bieber', 'popularity': 100.0}, {'name': 'Bad Bunny', 'popularity': 98.0}, {'name': 'Taylor Swift', 'popularity': 98.0}, {'name': 'Drake', 'popularity': 98.0}, {'name': 'Juice WRLD', 'popularity': 96.0}]\n"
     ]
    }
   ],
   "source": [
    "print(extract_top5_DictReader(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488 ms ± 2.91 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2582.03 MiB, increment: 65.12 MiB\n",
      "168 ms ± 516 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2588.31 MiB, increment: 55.38 MiB\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def loading_from_csv_reader(filename):\n",
    "    with open(filename, encoding=\"utf8\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)  # Récupère les en-têtes\n",
    "        data = list(reader)    # Lit le reste des données\n",
    "    return header, data\n",
    "\n",
    "\n",
    "\n",
    "def extract_top5_reader(header, data):\n",
    "    # Trouver l'index des colonnes 'name' et 'popularity'\n",
    "    name_idx = header.index('name')\n",
    "    popularity_idx = header.index('popularity')\n",
    "\n",
    "    # Trier les données en fonction de la popularité\n",
    "    top5_artists = sorted(data, key=lambda x: float(x[popularity_idx]), reverse=True)[:5]\n",
    "\n",
    "    # Retourner les noms et popularités des 5 meilleurs artistes\n",
    "    return [{'name': artist[name_idx], 'popularity': float(artist[popularity_idx])} for artist in top5_artists]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "time_measures[\"csv_reader_load\"] = %timeit -o -r 3 -n 10 loading_from_csv_reader(filename)\n",
    "memory_measures[\"csv_reader_load\"] = %memit -c -o -r 3 -i 0.001 loading_from_csv_reader(filename)\n",
    "\n",
    "header,data = loading_from_csv_reader(filename)\n",
    "\n",
    "time_measures[\"csv_reader_extract\"] = %timeit -o -r 3 -n 10 extract_top5_reader(header, data)\n",
    "memory_measures[\"csv_reader_extract\"] = %memit -c -o -r 3 -i 0.001 extract_top5_reader(header, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "730 ms ± 4.18 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2785.19 MiB, increment: 58.05 MiB\n",
      "85.3 ms ± 562 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2494.81 MiB, increment: 55.72 MiB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loading_from_pandas_csv(filename):\n",
    "    return pd.read_csv(filename, encoding=\"utf8\")\n",
    "\n",
    "\n",
    "def extract_top5_pandas(data):\n",
    "    # Trier les données par popularité et sélectionner les 5 premières lignes\n",
    "    sorted_data = data.sort_values(by=\"popularity\", ascending=False).head(5)\n",
    "    return sorted_data[[\"name\", \"popularity\"]]\n",
    "\n",
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n",
    "\n",
    "time_measures[\"pandas_csv_load\"] = %timeit -o -r 3 -n 10 loading_from_pandas_csv (filename)\n",
    "memory_measures[\"pandas_csv_load\"] = %memit -c -o -r 3 -i 0.001 loading_from_pandas_csv (filename)\n",
    "\n",
    "data = loading_from_pandas_csv(filename)\n",
    "\n",
    "time_measures[\"pandas_csv_extract\"] = %timeit -o -r 3 -n 10 extract_top5_pandas(data)\n",
    "memory_measures[\"pandas_csv_extract\"] = %memit -c -o -r 3 -i 0.001 extract_top5_pandas(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "415 ms ± 1.99 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2497.16 MiB, increment: 57.53 MiB\n",
      "58.5 ms ± 311 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2151.00 MiB, increment: 55.38 MiB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loading_from_pandas_csv_optimized(filename):\n",
    "    return pd.read_csv(filename, encoding=\"utf8\", usecols=['name', 'popularity'])\n",
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n",
    "\n",
    "time_measures[\"pandas_csv_optim_load\"] = %timeit -o -r 3 -n 10 loading_from_pandas_csv_optimized(filename)\n",
    "memory_measures[\"pandas_csv_optim_load\"] = %memit -c -o -r 3 -i 0.001 loading_from_pandas_csv_optimized(filename)\n",
    "\n",
    "data = loading_from_pandas_csv_optimized(filename)\n",
    "\n",
    "time_measures[\"pandas_csv_optim_extract\"] = %timeit -o -r 3 -n 10 extract_top5_pandas(data)\n",
    "memory_measures[\"pandas_csv_optim_extract\"] = %memit -c -o -r 3 -i 0.001 extract_top5_pandas(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2365.03 MiB, increment: 270.41 MiB\n"
     ]
    }
   ],
   "source": [
    "res=%memit -c -o -i 0.001 loading_from_csv_DictReader(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2365.03125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2094.625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(res.mem_usage, res.baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "374 ms ± 15.8 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2606.20 MiB, increment: 402.50 MiB\n",
      "88.9 ms ± 3.03 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2251.94 MiB, increment: 56.23 MiB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parquet_filename = filename.replace('.csv', '.parquet')\n",
    "\n",
    "# Lire le fichier CSV et le convertir en fichier Parquet\n",
    "pd.read_csv(filename, encoding=\"utf8\").to_parquet(parquet_filename)\n",
    "\n",
    "\n",
    "def loading_from_pandas_parquet(filename):\n",
    "    return pd.read_parquet(filename)\n",
    "\n",
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n",
    "\n",
    "time_measures[\"pandas_parquet_load\"] = %timeit -o -r 3 -n 10 loading_from_pandas_parquet(filename[:-3]+\"parquet\")\n",
    "memory_measures[\"pandas_parquet_load\"] = %memit -c -o -r 3 -i 0.001 loading_from_pandas_parquet(filename[:-3]+\"parquet\")\n",
    "\n",
    "\n",
    "data = loading_from_pandas_parquet(filename[:-3]+\"parquet\")\n",
    "\n",
    "\n",
    "time_measures[\"pandas_parquet_extract\"] = %timeit -o -r 3 -n 10 extract_top5_pandas(data)\n",
    "memory_measures[\"pandas_parquet_extract\"] = %memit -c -o -r 3 -i 0.001 extract_top5_pandas(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "49.6 ms ± 448 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2202.64 MiB, increment: 56.11 MiB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "sqlite_filename = filename.replace('.csv', '.sqlite3')\n",
    "\n",
    "# Conversion du fichier CSV en base de données SQLite\n",
    "df = pd.read_csv(filename, encoding=\"utf8\")\n",
    "\n",
    "conn = sqlite3.connect(sqlite_filename)\n",
    "\n",
    "df.to_sql('artists', conn, if_exists='replace', index=False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_top5_sqlite(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    query = \"\"\"\n",
    "    \n",
    "    SELECT name, popularity \n",
    "    FROM artists \n",
    "    ORDER BY popularity DESC \n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    \n",
    "    top5_artists = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return top5_artists\n",
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n",
    "time_measures[\"sql_extract\"] = %timeit -o -r 3 -n 10 extract_top5_sqlite(filename[:-3]+\"sqlite3\")\n",
    "memory_measures[\"sql_extract\"] = %memit -c -o -r 3 -i 0.001 extract_top5_sqlite(filename[:-3]+\"sqlite3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes : 1325180\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "\n",
    "filename_csv = filename\n",
    "filename_sqlite = filename_csv.replace('.csv', '.sqlite3')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(filename_csv, encoding=\"utf8\")\n",
    "conn = sqlite3.connect(filename_sqlite)\n",
    "df.to_sql('artists', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def top5_genres(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    query = \"\"\"\n",
    "    SELECT json_each.value AS genre, popularity\n",
    "    FROM Artists, json_each(genres)\n",
    "    \"\"\"\n",
    "    top_genres = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return top_genres\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data2 = top5_genres(filename_sqlite)\n",
    "print(\"Nombre de lignes :\", len(data2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "47.2 ms ± 363 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "peak memory: 2281.09 MiB, increment: 58.20 MiB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "\n",
    "def top5_genres(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    query = \"\"\"\n",
    "    SELECT genre, AVG(popularity) as avg_popularity\n",
    "    FROM (\n",
    "        SELECT json_each.value AS genre, popularity\n",
    "        FROM artists, json_each(artists.genres)\n",
    "    )\n",
    "    GROUP BY genre\n",
    "    ORDER BY avg_popularity DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    top_genres = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return top_genres\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n",
    "time_measures[\"sql_extract\"] = %timeit -o -r 3 -n 10 extract_top5_sqlite(filename[:-3]+\"sqlite3\")\n",
    "memory_measures[\"sql_extract\"] = %memit -c -o -r 3 -i 0.001 extract_top5_sqlite(filename[:-3]+\"sqlite3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csv_dictreader_load': <TimeitResult : 946 ms ± 15.8 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'csv_dictreader_extract': <TimeitResult : 171 ms ± 7.71 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'csv_reader_load': <TimeitResult : 488 ms ± 2.91 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'csv_reader_extract': <TimeitResult : 168 ms ± 516 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'pandas_csv_load': <TimeitResult : 730 ms ± 4.18 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'pandas_csv_extract': <TimeitResult : 85.3 ms ± 562 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'pandas_csv_optim_load': <TimeitResult : 415 ms ± 1.99 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'pandas_csv_optim_extract': <TimeitResult : 58.5 ms ± 311 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'pandas_parquet_load': <TimeitResult : 374 ms ± 15.8 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'pandas_parquet_extract': <TimeitResult : 88.9 ms ± 3.03 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)>,\n",
       " 'sql_extract': <TimeitResult : 47.2 ms ± 363 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)>}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csv_dictreader_load': <MemitResult : peak memory: 2177.33 MiB, increment: 426.41 MiB>,\n",
       " 'csv_dictreader_extract': <MemitResult : peak memory: 2196.59 MiB, increment: 55.38 MiB>,\n",
       " 'csv_reader_load': <MemitResult : peak memory: 2582.03 MiB, increment: 65.12 MiB>,\n",
       " 'csv_reader_extract': <MemitResult : peak memory: 2588.31 MiB, increment: 55.38 MiB>,\n",
       " 'pandas_csv_load': <MemitResult : peak memory: 2785.19 MiB, increment: 58.05 MiB>,\n",
       " 'pandas_csv_extract': <MemitResult : peak memory: 2494.81 MiB, increment: 55.72 MiB>,\n",
       " 'pandas_csv_optim_load': <MemitResult : peak memory: 2497.16 MiB, increment: 57.53 MiB>,\n",
       " 'pandas_csv_optim_extract': <MemitResult : peak memory: 2151.00 MiB, increment: 55.38 MiB>,\n",
       " 'pandas_parquet_load': <MemitResult : peak memory: 2606.20 MiB, increment: 402.50 MiB>,\n",
       " 'pandas_parquet_extract': <MemitResult : peak memory: 2251.94 MiB, increment: 56.23 MiB>,\n",
       " 'sql_extract': <MemitResult : peak memory: 2281.09 MiB, increment: 58.20 MiB>}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_measures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
